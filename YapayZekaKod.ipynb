{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TensorFlow ve Keras kÃ¼tÃ¼phanelerini iÃ§e aktar\n",
    "import tensorflow as tf\n",
    "\n",
    "# Resim iÅŸleme iÃ§in kullanÄ±lan kÃ¼tÃ¼phaneler\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array\n",
    "\n",
    "# NumPy, dizilerle Ã§alÄ±ÅŸmak iÃ§in gerekli\n",
    "import numpy as np\n",
    "\n",
    "# Ä°ÅŸletim sistemi iÅŸlemleri iÃ§in os modÃ¼lÃ¼\n",
    "import os\n",
    "\n",
    "# OpenCV ile gÃ¶rÃ¼ntÃ¼ iÅŸleme\n",
    "import cv2\n",
    "\n",
    "# Grafikleri Ã§izmek iÃ§in Matplotlib\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Veri seti boyutu: (114, 224, 224, 3)\n"
     ]
    }
   ],
   "source": [
    "# ğŸ“‚ kartal ve kurt resimlerinin bulunduÄŸu ana klasÃ¶rleri tanÄ±mla\n",
    "train_dir = \"C:/Users/FUJITSU/OneDrive/MasaÃ¼stÃ¼/yapayzeka/test\"  # EÄŸitim verisi klasÃ¶rÃ¼\n",
    "test_dir = \"C:/Users/FUJITSU/OneDrive/MasaÃ¼stÃ¼/yapayzeka/train\"    # Test verisi klasÃ¶rÃ¼\n",
    "\n",
    "# ğŸ“ Resim boyutlarÄ±nÄ± belirle (CNN modeline uygun hale getirmek iÃ§in)\n",
    "IMG_WIDTH, IMG_HEIGHT = 224, 224\n",
    "\n",
    "# ğŸ· SÄ±nÄ±f etiketlerini tanÄ±mla (0: kartal, 1: kurt)\n",
    "classes = ['eagle', 'wolf']\n",
    "\n",
    "# ğŸ“¦ BoÅŸ listeler oluÅŸtur (Resimler ve etiketler iÃ§in)\n",
    "X, Y = [], []\n",
    "\n",
    "# ğŸ”„ Resimleri oku ve Ã¶n iÅŸleme tabi tut\n",
    "for class_name in classes:\n",
    "    class_path = os.path.join(train_dir, class_name)  # SÄ±nÄ±fa ait klasÃ¶r yolu\n",
    "    for img_name in os.listdir(class_path):  # KlasÃ¶rdeki her bir resmi oku\n",
    "        img_path = os.path.join(class_path, img_name)  # Resmin tam yolunu al\n",
    "        img = load_img(img_path, target_size=(IMG_WIDTH, IMG_HEIGHT))  # Resmi oku ve boyutlandÄ±r\n",
    "        img_array = img_to_array(img) / 255.0  # Resmi normalize et (0-1 aralÄ±ÄŸÄ±na getir)\n",
    "        X.append(img_array)  # Listeye ekle\n",
    "        Y.append(classes.index(class_name))  # kartal = 0, Kurt = 1 olarak etiketle\n",
    "\n",
    "# ğŸ“Š Listeleri NumPy dizisine Ã§evir\n",
    "X = np.array(X)\n",
    "Y = np.array(Y)\n",
    "\n",
    "# âœ… Veri setinin boyutunu ekrana yazdÄ±r\n",
    "print(f\"Veri seti boyutu: {X.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸ“Œ Derin Ã¶ÄŸrenme modeli (CNN) oluÅŸturuluyor\n",
    "model = tf.keras.Sequential([\n",
    "    # ğŸ¯ Ä°lk katman: 32 filtreli 3x3 konvolÃ¼syon katmanÄ± (Aktivasyon fonksiyonu: ReLU)\n",
    "    tf.keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=(IMG_WIDTH, IMG_HEIGHT, 3)),\n",
    "    \n",
    "    # ğŸ”½ Max Pooling: 2x2 boyutunda havuzlama iÅŸlemi (Ã–zellikleri kÃ¼Ã§Ã¼ltmek iÃ§in)\n",
    "    tf.keras.layers.MaxPooling2D(2, 2),\n",
    "    \n",
    "    # ğŸ¯ Ä°kinci konvolÃ¼syon katmanÄ± (64 filtre, 3x3 kernel)\n",
    "    tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(2, 2),\n",
    "\n",
    "    # ğŸ¯ ÃœÃ§Ã¼ncÃ¼ konvolÃ¼syon katmanÄ± (128 filtre, 3x3 kernel)\n",
    "    tf.keras.layers.Conv2D(128, (3, 3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(2, 2),\n",
    "\n",
    "    # ğŸ”„ DÃ¼zleÅŸtirme katmanÄ± (Flatten)\n",
    "    tf.keras.layers.Flatten(),\n",
    "\n",
    "    # ğŸ”¢ Tam baÄŸlÄ± katman (128 nÃ¶ronlu, aktivasyon fonksiyonu ReLU)\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "\n",
    "    # ğŸ· Ã‡Ä±kÄ±ÅŸ katmanÄ±: 2 nÃ¶ron (Kedi veya KÃ¶pek), Softmax aktivasyon fonksiyonu\n",
    "    tf.keras.layers.Dense(2, activation='softmax')\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸ“Œ Modeli derle\n",
    "model.compile(\n",
    "    optimizer='adam',  # Optimizasyon algoritmasÄ± (Adam)\n",
    "    loss='sparse_categorical_crossentropy',  # Kategorik Ã§apraz entropi kaybÄ±\n",
    "    metrics=['accuracy']  # BaÅŸarÄ± metriÄŸi: DoÄŸruluk oranÄ±\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m3/3\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 5s/step - accuracy: 0.5364 - loss: 1.4503 - val_accuracy: 0.0000e+00 - val_loss: 3.1178\n",
      "Epoch 2/5\n",
      "\u001b[1m3/3\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 4s/step - accuracy: 0.6186 - loss: 0.9950 - val_accuracy: 1.0000 - val_loss: 0.6485\n",
      "Epoch 3/5\n",
      "\u001b[1m3/3\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 4s/step - accuracy: 0.6062 - loss: 0.6704 - val_accuracy: 0.0000e+00 - val_loss: 0.9932\n",
      "Epoch 4/5\n",
      "\u001b[1m3/3\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 4s/step - accuracy: 0.7252 - loss: 0.6083 - val_accuracy: 0.0870 - val_loss: 0.8780\n",
      "Epoch 5/5\n",
      "\u001b[1m3/3\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 4s/step - accuracy: 0.7611 - loss: 0.5445 - val_accuracy: 1.0000 - val_loss: 0.1297\n"
     ]
    }
   ],
   "source": [
    "# ğŸ“Œ Modeli eÄŸit ve doÄŸrulama verisi kullanarak test et\n",
    "history = model.fit(X, Y, epochs=5, validation_split=0.2)  # EÄŸitim verisinin %20â€™si doÄŸrulama iÃ§in kullanÄ±lacak\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EÄŸitim DoÄŸruluÄŸu: 0.7253\n",
      "DoÄŸrulama DoÄŸruluÄŸu: 1.0000\n"
     ]
    }
   ],
   "source": [
    "# ğŸ¯ EÄŸitim ve doÄŸrulama doÄŸruluk oranlarÄ±nÄ± al\n",
    "train_acc = history.history['accuracy'][-1]\n",
    "val_acc = history.history['val_accuracy'][-1]\n",
    "\n",
    "# ğŸ“Š SonuÃ§larÄ± ekrana yazdÄ±r\n",
    "print(f\"EÄŸitim DoÄŸruluÄŸu: {train_acc:.4f}\")\n",
    "print(f\"DoÄŸrulama DoÄŸruluÄŸu: {val_acc:.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "yapayzeka",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
